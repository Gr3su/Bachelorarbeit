\section{Kompression und Analyse}
Zur Kompression und Analyse sind gewisse Parameter einzustellen: einerseits um unterschiedliche Kompressionsraten zu erzielen, andererseits um einen bestimmten Prozentsatz an Ausreißern zu erkennen oder um einen Schwellwert für die Ausreißererkennung festzulegen.

\renewcommand{\tabledata}[4]{\phantom{000}\llap{#1} & \phantom{000}\llap{#2} & \phantom{000}\llap{#3} & \phantom{000}\llap{#4}\\}
\begin{table}[b]
 \centering
 \begin{tabular}{lc|cccc}
  \toprule
  \multicolumn{1}{c}{\bfseries Daten} & \boldmath $\rho$ & \bfseries Linear & \bfseries Polynomiell & \bfseries Fourier & \bfseries Wavelet \\
  \midrule
  \multirow{3}{*}{Wetterdaten} & 0,50 & \tabledata{15}{32}{15}{3}
  & 0,25 & \tabledata{35}{75}{5}{4}
  & 0,10 & \tabledata{95}{200}{2}{6}
  \midrule
  \multirow{3}{*}{NVIDIA-Aktie} & 0,50 & \tabledata{5}{9}{100}{1}
  & 0,25 & \tabledata{9}{20}{30}{2}
  & 0,10 & \tabledata{30}{50}{1}{4}
  \midrule
  \multirow{3}{*}{ECG5000} & 0,50 & \tabledata{7}{15}{50}{2}
  & 0,25 & \tabledata{14}{30}{20}{3}
  & 0,10 & \tabledata{35}{100}{8}{4}
  \bottomrule
 \end{tabular}
 \caption{Parameter zur Kompression}
 \label{tbl:metrikenKompression}
\end{table}

Der im Folgenden verwendete Begriff der Kompressionsrate $\rho$ ist in \cite[Ch. 3.3]{compressionSurvey} als $\rho = \frac{s'}{s}$ definiert, wobei $s'$ die komprimierte Größe der Zeitreihe ist und $s$ die Größe der originalen Zeitreihe. Um die späteren Analysen auf verschieden stark komprimierten Daten zu testen, haben wir uns für drei Kompressionsraten entschieden. Gewählt wurden 50\%, 25\% und 10\% der ursprünglichen Dateigröße. Die beiden größeren Zielgrößen orientieren sich an typischen Anwendungsfällen aus der Praxis, wohingegen die kleinste Zielgröße der Analyse eines Extremfalls dient. In \autoref{tbl:metrikenKompression} sieht man die Parameter der Kompressionsverfahren, die in ihrer aufgeführten Reihenfolge an das Skript aus \autoref{lst:surveyExecution} übergeben werden müssen, um die gewünschten Kompressionsraten zu erzielen.

Die tatsächliche Kompressionsrate einer Zeitreihe wurde anhand der Text"=Dateigröße in Bytes ermittelt. Vorteilhaft an dieser Herangehensweise ist, dass man den tatsächlichen Speicherverbrauch betrachtet, der in der Praxis der relevante Wert beim Komprimieren ist. Nachteilhaft ist allerdings, dass man daran nicht den Informationsgehalt der komprimierten Zeitreihe festlegen kann. Damit ist gemeint, dass zwei Zeitreihen zwar gleich viele Werte haben können, sich ihr Platzbedarf jedoch unterscheidet: besitzen die Werte der einen Zeitreihe nur eine Nachkommastelle, so benötigt sie weniger Platz als eine Zeitreihe, deren Werte mit mindestens zehn Nachkommastellen gespeichert werden. 

\renewcommand{\tabledata}[4]{\phantom{000}\llap{#1} & \phantom{000}\llap{#2} & \phantom{000}\llap{#3} & \phantom{000}\llap{#4}\\}
\begin{table}[t]
 \centering
 \begin{tabular}{lc|ccccc}
  \toprule
  \multicolumn{1}{c}{\bfseries Daten} & \boldmath $\rho$ & \bfseries Original & \bfseries Linear & \bfseries Polynomiell & \bfseries Fourier & \bfseries Wavelet \\ 
  \midrule
   \multirow{3}{*}{Wetterdaten} & 0,50 & \multirow{3}{*}{1000} & \tabledata{134}{128}{310}{125}
   & 0,25 & & \tabledata{58}{56}{141}{63}
   & 0,10 & & \tabledata{22}{20}{89}{16}
   \midrule
   \multirow{3}{*}{NVIDIA-Aktie} & 0,50 & \multirow{3}{*}{\phantom{00}50} & \tabledata{20}{24}{25}{25}
   & 0,25 & & \tabledata{12}{12}{25}{13}
   & 0,10 & & \tabledata{4}{4}{25}{4}
   \midrule
   \multirow{3}{*}{ECG5000} & 0,50 & \multirow{3}{*}{\phantom{0}140} & \tabledata{40}{40}{70}{35}
   & 0,25 & & \tabledata{20}{20}{56}{18}
   & 0,10 & & \tabledata{8}{8}{17}{9}
  \bottomrule
 \end{tabular}
 \caption{Anzahl der durchschnittlichen Double"=Werte}
 \label{tbl:kompressionsratenDoubleWerte}
\end{table}

\renewcommand{\tabledata}[4]{\phantom{0000}\llap{#1} & \phantom{0000}\llap{#2} & \phantom{0000}\llap{#3} & \phantom{0000}\llap{#4}\\}
\begin{table}[t]
 \centering
 \begin{tabular}{lc|ccccc}
  \toprule
  \multicolumn{1}{c}{\bfseries Daten} & \boldmath $\rho$ & \bfseries Original & \bfseries Linear & \bfseries Polynomiell & \bfseries Fourier & \bfseries Wavelet \\ 
  \midrule
   \multirow{3}{*}{Wetterdaten} & 0,50 & \multirow{3}{*}{4543} & \tabledata{2565}{2641}{2629}{2436}
   & 0,25 & & \tabledata{1131}{1181}{1052}{1196}
   & 0,10 & & \tabledata{427}{427}{575}{310}
   \midrule
   \multirow{3}{*}{NVIDIA-Aktie} & 0,50 & \multirow{3}{*}{1103} & \tabledata{445}{540}{518}{554}
   & 0,25 & & \tabledata{267}{273}{247}{287}
   & 0,10 & & \tabledata{88}{91}{138}{86}
   \midrule
   \multirow{3}{*}{ECG5000} & 0,50 & \multirow{3}{*}{1702} & \tabledata{818}{877}{848}{651}
   & 0,25 & & \tabledata{405}{440}{480}{362}
   & 0,10 & & \tabledata{163}{176}{169}{178}
  \bottomrule
 \end{tabular}
 \caption{Durchschnittliche Dateigröße in Bytes}
 \label{tbl:kompressionsratenBytes}
\end{table}

Während in der \autoref{tbl:kompressionsratenBytes} die Dateigrößen einer Zeitreihe in Bytes zu finden sind, sind in \autoref{tbl:kompressionsratenDoubleWerte} die Anzahl der Double"=Werte einer Zeitreihe zu finden. Die Double"=Werte sind dazu da, den Informationsgehalt der Zeitreihen zu bewerten und Rückschlüsse darauf ziehen zu können, wie viel Platz eine Zeitreihe in Form eines Arrays verbrauchen würde. Die Werte in \autoref{tbl:kompressionsratenDoubleWerte} und \autoref{tbl:kompressionsratenBytes} sind über alle Zeitreihen einer Kategorie (Original, Linear"=approximiert, \dots) gemittelt und gerundet. In \autoref{tbl:kompressionsratenBytes} fällt auf, dass mit der Wavelet"=Transformation nicht immer exakt die Kompressionsraten erreicht werden konnten. Das hängt damit zusammen, dass die Anzahl der Werte immer nur halbiert werden kann und somit keine beliebigen Kompressionsraten realisierbar sind. Aus demselben Grund, aus dem wir die Anzahl der Double"=Werte angeben, entspricht eine Halbierung der Double"=Werte nicht zwangsläufig einer Halbierung der Text-Dateigröße. Bei den anderen Kompressionsverfahren wurde versucht, zwei Bedingungen bestmöglich zu erfüllen, und zwar dass die eigentliche Kompressionsrate erreicht wird und man gleichzeitig nicht allzu weit weg von der tatsächlichen Kompressionsrate der Wavelet"=Transformation ist.

Bei den Ausreißererkennungsverfahren wurden keine eigenen Parameter gesetzt, sondern die Standardwerte der jeweiligen Funktionen übernommen. Das hat vor allem zwei Gründe, einerseits sind die gesetzten Parameter etablierte Standardwerte, die auch in \autoref{ch:theoretischegrundlagen} bei den jeweiligen Verfahren genannt werden, andererseits liegt der Fokus der Arbeit darauf, wie gut die Analyseverfahren die vermeintlichen Ausreißer in den originalen Daten auch in den komprimierten Daten finden. Ob diese Daten tatsächlich Ausreißer sind, ist dafür nicht relevant. Bei dem Verfahren für Ähnlichkeitssuche muss hingegen angegeben werden, wie viele nächste Nachbarn man zurückgeben möchte. In unserem Fall haben wir diesen auf 100 gesetzt, denn ein zu kleiner Wert wäre zu anfällig für Rauschen, also dass ein paar wenige Werte in den komprimierten Daten nicht mehr als Nachbarn erkannt werden, und ein zu großer Wert verliert an Sinnhaftigkeit, da sich dann die Daten zu stark unterscheiden und nicht mehr "`ähnlich"' sind.