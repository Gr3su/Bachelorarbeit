\section{Verfahren zur Ausreißererkennung}

%\subsection{k"=Next"=Neighbors}

\subsection{Isolation Forest}
Das Isolation Forest oder iForest Verfahren zur Ausreißererkennung von Fei Tony Liu et al. \cite{iForest}, erkennt Ausreißer dadurch, dass sie leichter von anderen zu isolieren sind. Isolieren bedeutet hierbei das Abgrenzen eines Punktes von Anderen. Ausreißer sind leichter abzugrenzen, da sie zwei Eigenschaften besitzen:
\begin{enumerate}
    \item "`Ausreißer sind eine Minderheit, die aus wenigen [Datenpunkten] besteht"',
    \item "`Sie besitzen Werte die sich stark von denen, von normalen [Datenpunkten] unterscheiden"'
\end{enumerate}
(vergleiche \cite[Ch. 1]{iForest}, aus dem Englischen übersetzt) \\
iForest isoliert Datenpunkte, indem es sie zufällig rekursiv partitioniert, so lange bis nur noch ein Datenpunkt in einer Partition liegt. Diese zufällige Partitionierung sorgt dafür, dass Ausreißer mit nur wenigen Partitionen isoliert werden, da es nur wenige Datenpunkte sind, die sich von den anderen stark unterscheiden. Um diese Idee visuell zu verdeutlichen, veranschaulicht die \autoref{fig:partitionierungen} eine Isolierung von einem normalen Datenpunkt $x_i$ und von einem Ausreißer $x_0$. Dabei sind die kleinen Kreise die verschiedenen Datenpunkte und die schwarzen Linien die Grenzen der Partitionen. In \autoref{subfig:partitionierung1} sieht man nun, dass zur Isolierung von $x_i$ viele zufällige Partitionen benötigt werden. In \autoref{subfig:partitionierung2} sieht man wiederum, dass relativ schnell, mit nur zwei zufälligen Partitionen, $x_0$ isoliert werden konnte.
\begin{figure}[bth]
  \subfloat[Isolierung von $x_i$]{\includegraphics[width=0.49\textwidth]{Graphics/Partitionierung1.pdf}\label{subfig:partitionierung1}}\hfill
  \subfloat[Isolierung von $x_0$]{\includegraphics[width=0.49\textwidth]{Graphics/Partitionierung2.pdf}\label{subfig:partitionierung2}}\hfill
  \caption{Zufällige Partitionierung zur Isolierung zweier Punkte, angelehnt an \cite[Fig. 1]{iForest}}
  \label{fig:partitionierungen}
\end{figure}

Das rekursive Partitionieren lässt sich auch als Baum darstellen, wobei dann die Pfadlänge von der Wurzel zu einem Knoten genau der Anzahl der Partitionen entspricht. Daher kommt auch der Name iForest, da mehrere dieser Bäume zur Isolierung generiert werden, um, durch die zufällige Partitionierung, Partitionen mit verschiedenen Daten zu erhalten. Die durchschnittliche Pfadlänge der verschiedenen Datenpunkte ist dann die erwartete Pfadlänge. Die Baumstruktur baut sich wie folgt auf: Zuerst wird aus den Beobachtung in $ZR$ eine zufällige Teilmenge $X$ ausgesucht, meist nicht mehr als 256 Elemente, da dies zu genaueren Ergebnissen führt \cite[Ch. 4.1]{iForest}. Dann beginnt die Konstruktion des Baums, indem die Menge $X$ in die Wurzel des Baums geschrieben wird. Daraufhin wird ein zufälliges Feature ausgesucht und ein zufälliger Wert $p$, der zwischen dem Minimum und Maximum aus diesem Feature liegt. Die Menge $X$ wird dann entsprechend $p$ in zwei disjunkte Teilmengen aufgeteilt, wobei die kleineren Werte in den linken Kindknoten, und die größeren Werte in den rechten Kindknoten der Wurzel geschrieben werden. Die Schritte ab der Auswahl des zufälligen Features werden nun für die Kindknoten so lange fortgeführt, bis entweder:
\begin{itemize}
    \item "`der Baum eine maximale Höhe erreicht hat"',
    \item "`$|X|=1$"',
    \item beim zufällig ausgewählten Feature, "`alle Werte der Elemente in $X$  identisch sind"'.
\end{itemize}
(vergleiche \cite[Ch. 2]{iForest}, aus dem Englischen übersetzt) \\
Etwa 100 Bäume genügen \cite[Ch. 4.1]{iForest}, um keine signifikanten Unterschiede mehr in der durchschnittlichen Pfadlänge zwischen Wurzel und einem Knoten zu erhalten. Um dann einen zwischen Wurzel und einem Knoten zu erhalten. Um dann einen Ausreißer"=Score zu erhalten, wird folgende Formel angewandt:
\[ s(x,n)=2^{-\frac{E(h(x))}{c(n)}}, \]
wobei $|X|=n$, $c(n)=2H(n-1)-(2(n-1)/n)$, $H(i)=\ln(i) + 0,5772156649$ (Euler"=Mascheroni"=Konstante), $h(x)$ ist die Pfadlänge eines Knotens $x$ in einem Baum, also die Kantenanzahl von Wurzel bis zu diesem Knoten und $E(h(x))$ ist die durchschnittliche Kantenanzahl über alle Bäume. Diese Formel normalisiert die durchschnittliche Höhe und garantiert damit, dass wir immer $0 < s \le 1$ erhalten, für egal welches $n$ und $x$. Mit $s$ kann man nun drei Einschätzungen vornehmen:
\begin{itemize}
    \item "`ist das $s$ eines Knoten nah an 1, dann ist es definitiv ein Ausreißer"',
    \item "`ist das $s$ eines Knoten weit unter 0,5, dann kann man mit Sicherheit sagen, dass es ein normaler [Datenpunkt] ist"',
    \item "`geben alle [Datenpunkte] $s \approx 0,5$ zurück, dann gibt es keine auffälligen Ausreißer"'.
\end{itemize}
(vergleiche \cite[Ch. 2]{iForest}, aus dem Englischen übersetzt) \\